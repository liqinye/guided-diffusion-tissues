Logging to log
Worker 0: Creating logger
Worker 0: Creating model and diffusion...
Worker 0: Model loaded
Worker 0: Creating data loader...
Worker 0: The size of training set 131
Worker 0: The size of validation set 8
Worker 0: Training data loaded
Worker 0: Training started
Worker 0: Training loop constructed
----------------------------
| grad_norm     | 0.0114   |
| loss          | 0.0132   |
| mse           | 0.0132   |
| param_norm    | 404      |
| samples       | 32       |
| step          | 0        |
| train_loss_q0 | 0.0245   |
| train_loss_q1 | 0.00375  |
| train_loss_q3 | 6.17e-05 |
| train_mse_q0  | 0.0245   |
| train_mse_q1  | 0.00375  |
| train_mse_q3  | 6.17e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.0168   |
| loss          | 0.00394  |
| mse           | 0.00394  |
| param_norm    | 404      |
| samples       | 3.2e+04  |
| step          | 1e+03    |
| train_loss_q0 | 0.0125   |
| train_loss_q1 | 0.00294  |
| train_loss_q2 | 0.000287 |
| train_loss_q3 | 2.74e-05 |
| train_mse_q0  | 0.0125   |
| train_mse_q1  | 0.00294  |
| train_mse_q2  | 0.000287 |
| train_mse_q3  | 2.74e-05 |
----------------------------
----------------------------
| grad_norm     | 0.017    |
| loss          | 0.00437  |
| mse           | 0.00437  |
| param_norm    | 405      |
| samples       | 6.4e+04  |
| step          | 2e+03    |
| train_loss_q0 | 0.0137   |
| train_loss_q1 | 0.00284  |
| train_loss_q2 | 0.000342 |
| train_loss_q3 | 2.74e-05 |
| train_mse_q0  | 0.0137   |
| train_mse_q1  | 0.00284  |
| train_mse_q2  | 0.000342 |
| train_mse_q3  | 2.74e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0159   |
| loss          | 0.00402  |
| mse           | 0.00402  |
| param_norm    | 405      |
| samples       | 9.6e+04  |
| step          | 3e+03    |
| train_loss_q0 | 0.0129   |
| train_loss_q1 | 0.00272  |
| train_loss_q2 | 0.000318 |
| train_loss_q3 | 2.53e-05 |
| train_mse_q0  | 0.0129   |
| train_mse_q1  | 0.00272  |
| train_mse_q2  | 0.000318 |
| train_mse_q3  | 2.53e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0158   |
| loss          | 0.00409  |
| mse           | 0.00409  |
| param_norm    | 406      |
| samples       | 1.28e+05 |
| step          | 4e+03    |
| train_loss_q0 | 0.0134   |
| train_loss_q1 | 0.00269  |
| train_loss_q2 | 0.000279 |
| train_loss_q3 | 2.55e-05 |
| train_mse_q0  | 0.0134   |
| train_mse_q1  | 0.00269  |
| train_mse_q2  | 0.000279 |
| train_mse_q3  | 2.55e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0167   |
| loss          | 0.00393  |
| mse           | 0.00393  |
| param_norm    | 406      |
| samples       | 1.6e+05  |
| step          | 5e+03    |
| train_loss_q0 | 0.0129   |
| train_loss_q1 | 0.00263  |
| train_loss_q2 | 0.000311 |
| train_loss_q3 | 2.75e-05 |
| train_mse_q0  | 0.0129   |
| train_mse_q1  | 0.00263  |
| train_mse_q2  | 0.000311 |
| train_mse_q3  | 2.75e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0162   |
| loss          | 0.00372  |
| mse           | 0.00372  |
| param_norm    | 407      |
| samples       | 1.92e+05 |
| step          | 6e+03    |
| train_loss_q0 | 0.0123   |
| train_loss_q1 | 0.00274  |
| train_loss_q2 | 0.000288 |
| train_loss_q3 | 2.5e-05  |
| train_mse_q0  | 0.0123   |
| train_mse_q1  | 0.00274  |
| train_mse_q2  | 0.000288 |
| train_mse_q3  | 2.5e-05  |
----------------------------
----------------------------
| grad_norm     | 0.0171   |
| loss          | 0.00408  |
| mse           | 0.00408  |
| param_norm    | 408      |
| samples       | 2.24e+05 |
| step          | 7e+03    |
| train_loss_q0 | 0.0132   |
| train_loss_q1 | 0.0027   |
| train_loss_q2 | 0.000313 |
| train_loss_q3 | 2.74e-05 |
| train_mse_q0  | 0.0132   |
| train_mse_q1  | 0.0027   |
| train_mse_q2  | 0.000313 |
| train_mse_q3  | 2.74e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0158   |
| loss          | 0.00396  |
| mse           | 0.00396  |
| param_norm    | 408      |
| samples       | 2.56e+05 |
| step          | 8e+03    |
| train_loss_q0 | 0.013    |
| train_loss_q1 | 0.00263  |
| train_loss_q2 | 0.000315 |
| train_loss_q3 | 2.52e-05 |
| train_mse_q0  | 0.013    |
| train_mse_q1  | 0.00263  |
| train_mse_q2  | 0.000315 |
| train_mse_q3  | 2.52e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0162   |
| loss          | 0.00374  |
| mse           | 0.00374  |
| param_norm    | 409      |
| samples       | 2.88e+05 |
| step          | 9e+03    |
| train_loss_q0 | 0.012    |
| train_loss_q1 | 0.00265  |
| train_loss_q2 | 0.000298 |
| train_loss_q3 | 2.64e-05 |
| train_mse_q0  | 0.012    |
| train_mse_q1  | 0.00265  |
| train_mse_q2  | 0.000298 |
| train_mse_q3  | 2.64e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0159   |
| loss          | 0.00402  |
| mse           | 0.00402  |
| param_norm    | 409      |
| samples       | 3.2e+05  |
| step          | 1e+04    |
| train_loss_q0 | 0.0131   |
| train_loss_q1 | 0.00284  |
| train_loss_q2 | 0.000322 |
| train_loss_q3 | 2.52e-05 |
| train_mse_q0  | 0.0131   |
| train_mse_q1  | 0.00284  |
| train_mse_q2  | 0.000322 |
| train_mse_q3  | 2.52e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.0166   |
| loss          | 0.00406  |
| mse           | 0.00406  |
| param_norm    | 409      |
| samples       | 3.52e+05 |
| step          | 1.1e+04  |
| train_loss_q0 | 0.0131   |
| train_loss_q1 | 0.00294  |
| train_loss_q2 | 0.000319 |
| train_loss_q3 | 2.58e-05 |
| train_mse_q0  | 0.0131   |
| train_mse_q1  | 0.00294  |
| train_mse_q2  | 0.000319 |
| train_mse_q3  | 2.58e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0157   |
| loss          | 0.00442  |
| mse           | 0.00442  |
| param_norm    | 410      |
| samples       | 3.84e+05 |
| step          | 1.2e+04  |
| train_loss_q0 | 0.0142   |
| train_loss_q1 | 0.00278  |
| train_loss_q2 | 0.00032  |
| train_loss_q3 | 2.64e-05 |
| train_mse_q0  | 0.0142   |
| train_mse_q1  | 0.00278  |
| train_mse_q2  | 0.00032  |
| train_mse_q3  | 2.64e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0163   |
| loss          | 0.0042   |
| mse           | 0.0042   |
| param_norm    | 411      |
| samples       | 4.16e+05 |
| step          | 1.3e+04  |
| train_loss_q0 | 0.0138   |
| train_loss_q1 | 0.00273  |
| train_loss_q2 | 0.00032  |
| train_loss_q3 | 2.5e-05  |
| train_mse_q0  | 0.0138   |
| train_mse_q1  | 0.00273  |
| train_mse_q2  | 0.00032  |
| train_mse_q3  | 2.5e-05  |
----------------------------
----------------------------
| grad_norm     | 0.016    |
| loss          | 0.00412  |
| mse           | 0.00412  |
| param_norm    | 411      |
| samples       | 4.48e+05 |
| step          | 1.4e+04  |
| train_loss_q0 | 0.0131   |
| train_loss_q1 | 0.00266  |
| train_loss_q2 | 0.00033  |
| train_loss_q3 | 2.59e-05 |
| train_mse_q0  | 0.0131   |
| train_mse_q1  | 0.00266  |
| train_mse_q2  | 0.00033  |
| train_mse_q3  | 2.59e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0163   |
| loss          | 0.00397  |
| mse           | 0.00397  |
| param_norm    | 411      |
| samples       | 4.8e+05  |
| step          | 1.5e+04  |
| train_loss_q0 | 0.0125   |
| train_loss_q1 | 0.00263  |
| train_loss_q2 | 0.000309 |
| train_loss_q3 | 2.49e-05 |
| train_mse_q0  | 0.0125   |
| train_mse_q1  | 0.00263  |
| train_mse_q2  | 0.000309 |
| train_mse_q3  | 2.49e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0161   |
| loss          | 0.00357  |
| mse           | 0.00357  |
| param_norm    | 412      |
| samples       | 5.12e+05 |
| step          | 1.6e+04  |
| train_loss_q0 | 0.0115   |
| train_loss_q1 | 0.00276  |
| train_loss_q2 | 0.000312 |
| train_loss_q3 | 2.56e-05 |
| train_mse_q0  | 0.0115   |
| train_mse_q1  | 0.00276  |
| train_mse_q2  | 0.000312 |
| train_mse_q3  | 2.56e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0156   |
| loss          | 0.00409  |
| mse           | 0.00409  |
| param_norm    | 412      |
| samples       | 5.44e+05 |
| step          | 1.7e+04  |
| train_loss_q0 | 0.0133   |
| train_loss_q1 | 0.0026   |
| train_loss_q2 | 0.000294 |
| train_loss_q3 | 2.53e-05 |
| train_mse_q0  | 0.0133   |
| train_mse_q1  | 0.0026   |
| train_mse_q2  | 0.000294 |
| train_mse_q3  | 2.53e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0159   |
| loss          | 0.00421  |
| mse           | 0.00421  |
| param_norm    | 413      |
| samples       | 5.76e+05 |
| step          | 1.8e+04  |
| train_loss_q0 | 0.0133   |
| train_loss_q1 | 0.00285  |
| train_loss_q2 | 0.000308 |
| train_loss_q3 | 2.41e-05 |
| train_mse_q0  | 0.0133   |
| train_mse_q1  | 0.00285  |
| train_mse_q2  | 0.000308 |
| train_mse_q3  | 2.41e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0161   |
| loss          | 0.00438  |
| mse           | 0.00438  |
| param_norm    | 413      |
| samples       | 6.08e+05 |
| step          | 1.9e+04  |
| train_loss_q0 | 0.014    |
| train_loss_q1 | 0.00271  |
| train_loss_q2 | 0.000321 |
| train_loss_q3 | 2.74e-05 |
| train_mse_q0  | 0.014    |
| train_mse_q1  | 0.00271  |
| train_mse_q2  | 0.000321 |
| train_mse_q3  | 2.74e-05 |
----------------------------
----------------------------
| grad_norm     | 0.016    |
| loss          | 0.00414  |
| mse           | 0.00414  |
| param_norm    | 414      |
| samples       | 6.4e+05  |
| step          | 2e+04    |
| train_loss_q0 | 0.0135   |
| train_loss_q1 | 0.00282  |
| train_loss_q2 | 0.000307 |
| train_loss_q3 | 2.46e-05 |
| train_mse_q0  | 0.0135   |
| train_mse_q1  | 0.00282  |
| train_mse_q2  | 0.000307 |
| train_mse_q3  | 2.46e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.0161   |
| loss          | 0.00399  |
| mse           | 0.00399  |
| param_norm    | 414      |
| samples       | 6.72e+05 |
| step          | 2.1e+04  |
| train_loss_q0 | 0.0128   |
| train_loss_q1 | 0.00287  |
| train_loss_q2 | 0.000316 |
| train_loss_q3 | 2.46e-05 |
| train_mse_q0  | 0.0128   |
| train_mse_q1  | 0.00287  |
| train_mse_q2  | 0.000316 |
| train_mse_q3  | 2.46e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0159   |
| loss          | 0.00399  |
| mse           | 0.00399  |
| param_norm    | 415      |
| samples       | 7.04e+05 |
| step          | 2.2e+04  |
| train_loss_q0 | 0.0134   |
| train_loss_q1 | 0.00261  |
| train_loss_q2 | 0.000285 |
| train_loss_q3 | 2.48e-05 |
| train_mse_q0  | 0.0134   |
| train_mse_q1  | 0.00261  |
| train_mse_q2  | 0.000285 |
| train_mse_q3  | 2.48e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0158   |
| loss          | 0.00386  |
| mse           | 0.00386  |
| param_norm    | 415      |
| samples       | 7.36e+05 |
| step          | 2.3e+04  |
| train_loss_q0 | 0.0127   |
| train_loss_q1 | 0.00251  |
| train_loss_q2 | 0.000294 |
| train_loss_q3 | 2.51e-05 |
| train_mse_q0  | 0.0127   |
| train_mse_q1  | 0.00251  |
| train_mse_q2  | 0.000294 |
| train_mse_q3  | 2.51e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0163   |
| loss          | 0.00393  |
| mse           | 0.00393  |
| param_norm    | 416      |
| samples       | 7.68e+05 |
| step          | 2.4e+04  |
| train_loss_q0 | 0.0122   |
| train_loss_q1 | 0.0029   |
| train_loss_q2 | 0.00033  |
| train_loss_q3 | 2.6e-05  |
| train_mse_q0  | 0.0122   |
| train_mse_q1  | 0.0029   |
| train_mse_q2  | 0.00033  |
| train_mse_q3  | 2.6e-05  |
----------------------------
----------------------------
| grad_norm     | 0.0153   |
| loss          | 0.00405  |
| mse           | 0.00405  |
| param_norm    | 416      |
| samples       | 8e+05    |
| step          | 2.5e+04  |
| train_loss_q0 | 0.013    |
| train_loss_q1 | 0.0027   |
| train_loss_q2 | 0.000291 |
| train_loss_q3 | 2.4e-05  |
| train_mse_q0  | 0.013    |
| train_mse_q1  | 0.0027   |
| train_mse_q2  | 0.000291 |
| train_mse_q3  | 2.4e-05  |
----------------------------
----------------------------
| grad_norm     | 0.0162   |
| loss          | 0.00406  |
| mse           | 0.00406  |
| param_norm    | 417      |
| samples       | 8.32e+05 |
| step          | 2.6e+04  |
| train_loss_q0 | 0.0129   |
| train_loss_q1 | 0.00266  |
| train_loss_q2 | 0.000332 |
| train_loss_q3 | 2.64e-05 |
| train_mse_q0  | 0.0129   |
| train_mse_q1  | 0.00266  |
| train_mse_q2  | 0.000332 |
| train_mse_q3  | 2.64e-05 |
----------------------------
----------------------------
| grad_norm     | 0.016    |
| loss          | 0.00388  |
| mse           | 0.00388  |
| param_norm    | 417      |
| samples       | 8.64e+05 |
| step          | 2.7e+04  |
| train_loss_q0 | 0.0124   |
| train_loss_q1 | 0.00255  |
| train_loss_q2 | 0.000297 |
| train_loss_q3 | 2.56e-05 |
| train_mse_q0  | 0.0124   |
| train_mse_q1  | 0.00255  |
| train_mse_q2  | 0.000297 |
| train_mse_q3  | 2.56e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0161   |
| loss          | 0.00383  |
| mse           | 0.00383  |
| param_norm    | 418      |
| samples       | 8.96e+05 |
| step          | 2.8e+04  |
| train_loss_q0 | 0.0127   |
| train_loss_q1 | 0.00269  |
| train_loss_q2 | 0.000333 |
| train_loss_q3 | 2.76e-05 |
| train_mse_q0  | 0.0127   |
| train_mse_q1  | 0.00269  |
| train_mse_q2  | 0.000333 |
| train_mse_q3  | 2.76e-05 |
----------------------------
----------------------------
| grad_norm     | 0.015    |
| loss          | 0.00396  |
| mse           | 0.00396  |
| param_norm    | 418      |
| samples       | 9.28e+05 |
| step          | 2.9e+04  |
| train_loss_q0 | 0.0129   |
| train_loss_q1 | 0.00278  |
| train_loss_q2 | 0.000297 |
| train_loss_q3 | 2.5e-05  |
| train_mse_q0  | 0.0129   |
| train_mse_q1  | 0.00278  |
| train_mse_q2  | 0.000297 |
| train_mse_q3  | 2.5e-05  |
----------------------------
----------------------------
| grad_norm     | 0.015    |
| loss          | 0.00398  |
| mse           | 0.00398  |
| param_norm    | 418      |
| samples       | 9.6e+05  |
| step          | 3e+04    |
| train_loss_q0 | 0.013    |
| train_loss_q1 | 0.00274  |
| train_loss_q2 | 0.000326 |
| train_loss_q3 | 2.48e-05 |
| train_mse_q0  | 0.013    |
| train_mse_q1  | 0.00274  |
| train_mse_q2  | 0.000326 |
| train_mse_q3  | 2.48e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.0157   |
| loss          | 0.00394  |
| mse           | 0.00394  |
| param_norm    | 419      |
| samples       | 9.92e+05 |
| step          | 3.1e+04  |
| train_loss_q0 | 0.0125   |
| train_loss_q1 | 0.00279  |
| train_loss_q2 | 0.000307 |
| train_loss_q3 | 2.42e-05 |
| train_mse_q0  | 0.0125   |
| train_mse_q1  | 0.00279  |
| train_mse_q2  | 0.000307 |
| train_mse_q3  | 2.42e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0157   |
| loss          | 0.00399  |
| mse           | 0.00399  |
| param_norm    | 419      |
| samples       | 1.02e+06 |
| step          | 3.2e+04  |
| train_loss_q0 | 0.0133   |
| train_loss_q1 | 0.00266  |
| train_loss_q2 | 0.00029  |
| train_loss_q3 | 2.5e-05  |
| train_mse_q0  | 0.0133   |
| train_mse_q1  | 0.00266  |
| train_mse_q2  | 0.00029  |
| train_mse_q3  | 2.5e-05  |
----------------------------
----------------------------
| grad_norm     | 0.0153   |
| loss          | 0.00395  |
| mse           | 0.00395  |
| param_norm    | 420      |
| samples       | 1.06e+06 |
| step          | 3.3e+04  |
| train_loss_q0 | 0.0125   |
| train_loss_q1 | 0.00265  |
| train_loss_q2 | 0.000323 |
| train_loss_q3 | 2.58e-05 |
| train_mse_q0  | 0.0125   |
| train_mse_q1  | 0.00265  |
| train_mse_q2  | 0.000323 |
| train_mse_q3  | 2.58e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0149   |
| loss          | 0.00384  |
| mse           | 0.00384  |
| param_norm    | 420      |
| samples       | 1.09e+06 |
| step          | 3.4e+04  |
| train_loss_q0 | 0.0124   |
| train_loss_q1 | 0.00266  |
| train_loss_q2 | 0.0003   |
| train_loss_q3 | 2.35e-05 |
| train_mse_q0  | 0.0124   |
| train_mse_q1  | 0.00266  |
| train_mse_q2  | 0.0003   |
| train_mse_q3  | 2.35e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0161   |
| loss          | 0.00367  |
| mse           | 0.00367  |
| param_norm    | 421      |
| samples       | 1.12e+06 |
| step          | 3.5e+04  |
| train_loss_q0 | 0.0121   |
| train_loss_q1 | 0.00256  |
| train_loss_q2 | 0.000293 |
| train_loss_q3 | 2.61e-05 |
| train_mse_q0  | 0.0121   |
| train_mse_q1  | 0.00256  |
| train_mse_q2  | 0.000293 |
| train_mse_q3  | 2.61e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0149   |
| loss          | 0.00386  |
| mse           | 0.00386  |
| param_norm    | 421      |
| samples       | 1.15e+06 |
| step          | 3.6e+04  |
| train_loss_q0 | 0.0125   |
| train_loss_q1 | 0.00274  |
| train_loss_q2 | 0.000307 |
| train_loss_q3 | 2.55e-05 |
| train_mse_q0  | 0.0125   |
| train_mse_q1  | 0.00274  |
| train_mse_q2  | 0.000307 |
| train_mse_q3  | 2.55e-05 |
----------------------------
----------------------------
| grad_norm     | 0.016    |
| loss          | 0.00385  |
| mse           | 0.00385  |
| param_norm    | 422      |
| samples       | 1.18e+06 |
| step          | 3.7e+04  |
| train_loss_q0 | 0.0127   |
| train_loss_q1 | 0.00256  |
| train_loss_q2 | 0.000296 |
| train_loss_q3 | 2.57e-05 |
| train_mse_q0  | 0.0127   |
| train_mse_q1  | 0.00256  |
| train_mse_q2  | 0.000296 |
| train_mse_q3  | 2.57e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0157   |
| loss          | 0.00408  |
| mse           | 0.00408  |
| param_norm    | 422      |
| samples       | 1.22e+06 |
| step          | 3.8e+04  |
| train_loss_q0 | 0.0133   |
| train_loss_q1 | 0.00275  |
| train_loss_q2 | 0.000291 |
| train_loss_q3 | 2.67e-05 |
| train_mse_q0  | 0.0133   |
| train_mse_q1  | 0.00275  |
| train_mse_q2  | 0.000291 |
| train_mse_q3  | 2.67e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0151   |
| loss          | 0.00409  |
| mse           | 0.00409  |
| param_norm    | 423      |
| samples       | 1.25e+06 |
| step          | 3.9e+04  |
| train_loss_q0 | 0.0133   |
| train_loss_q1 | 0.00256  |
| train_loss_q2 | 0.000307 |
| train_loss_q3 | 2.48e-05 |
| train_mse_q0  | 0.0133   |
| train_mse_q1  | 0.00256  |
| train_mse_q2  | 0.000307 |
| train_mse_q3  | 2.48e-05 |
----------------------------
----------------------------
| grad_norm     | 0.016    |
| loss          | 0.00404  |
| mse           | 0.00404  |
| param_norm    | 423      |
| samples       | 1.28e+06 |
| step          | 4e+04    |
| train_loss_q0 | 0.0131   |
| train_loss_q1 | 0.00274  |
| train_loss_q2 | 0.00031  |
| train_loss_q3 | 2.54e-05 |
| train_mse_q0  | 0.0131   |
| train_mse_q1  | 0.00274  |
| train_mse_q2  | 0.00031  |
| train_mse_q3  | 2.54e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.0155   |
| loss          | 0.00389  |
| mse           | 0.00389  |
| param_norm    | 424      |
| samples       | 1.31e+06 |
| step          | 4.1e+04  |
| train_loss_q0 | 0.0122   |
| train_loss_q1 | 0.00267  |
| train_loss_q2 | 0.000305 |
| train_loss_q3 | 2.6e-05  |
| train_mse_q0  | 0.0122   |
| train_mse_q1  | 0.00267  |
| train_mse_q2  | 0.000305 |
| train_mse_q3  | 2.6e-05  |
----------------------------
----------------------------
| grad_norm     | 0.0145   |
| loss          | 0.00403  |
| mse           | 0.00403  |
| param_norm    | 424      |
| samples       | 1.34e+06 |
| step          | 4.2e+04  |
| train_loss_q0 | 0.0133   |
| train_loss_q1 | 0.00253  |
| train_loss_q2 | 0.000305 |
| train_loss_q3 | 2.41e-05 |
| train_mse_q0  | 0.0133   |
| train_mse_q1  | 0.00253  |
| train_mse_q2  | 0.000305 |
| train_mse_q3  | 2.41e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0153   |
| loss          | 0.00389  |
| mse           | 0.00389  |
| param_norm    | 424      |
| samples       | 1.38e+06 |
| step          | 4.3e+04  |
| train_loss_q0 | 0.013    |
| train_loss_q1 | 0.00243  |
| train_loss_q2 | 0.000333 |
| train_loss_q3 | 2.57e-05 |
| train_mse_q0  | 0.013    |
| train_mse_q1  | 0.00243  |
| train_mse_q2  | 0.000333 |
| train_mse_q3  | 2.57e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0154   |
| loss          | 0.00409  |
| mse           | 0.00409  |
| param_norm    | 425      |
| samples       | 1.41e+06 |
| step          | 4.4e+04  |
| train_loss_q0 | 0.0129   |
| train_loss_q1 | 0.00278  |
| train_loss_q2 | 0.000287 |
| train_loss_q3 | 2.51e-05 |
| train_mse_q0  | 0.0129   |
| train_mse_q1  | 0.00278  |
| train_mse_q2  | 0.000287 |
| train_mse_q3  | 2.51e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0149   |
| loss          | 0.00384  |
| mse           | 0.00384  |
| param_norm    | 425      |
| samples       | 1.44e+06 |
| step          | 4.5e+04  |
| train_loss_q0 | 0.0125   |
| train_loss_q1 | 0.00264  |
| train_loss_q2 | 0.00031  |
| train_loss_q3 | 2.43e-05 |
| train_mse_q0  | 0.0125   |
| train_mse_q1  | 0.00264  |
| train_mse_q2  | 0.00031  |
| train_mse_q3  | 2.43e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0148   |
| loss          | 0.00388  |
| mse           | 0.00388  |
| param_norm    | 426      |
| samples       | 1.47e+06 |
| step          | 4.6e+04  |
| train_loss_q0 | 0.0123   |
| train_loss_q1 | 0.00258  |
| train_loss_q2 | 0.000324 |
| train_loss_q3 | 2.37e-05 |
| train_mse_q0  | 0.0123   |
| train_mse_q1  | 0.00258  |
| train_mse_q2  | 0.000324 |
| train_mse_q3  | 2.37e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0159   |
| loss          | 0.00391  |
| mse           | 0.00391  |
| param_norm    | 426      |
| samples       | 1.5e+06  |
| step          | 4.7e+04  |
| train_loss_q0 | 0.0125   |
| train_loss_q1 | 0.00271  |
| train_loss_q2 | 0.000322 |
| train_loss_q3 | 2.58e-05 |
| train_mse_q0  | 0.0125   |
| train_mse_q1  | 0.00271  |
| train_mse_q2  | 0.000322 |
| train_mse_q3  | 2.58e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0147   |
| loss          | 0.00391  |
| mse           | 0.00391  |
| param_norm    | 427      |
| samples       | 1.54e+06 |
| step          | 4.8e+04  |
| train_loss_q0 | 0.0126   |
| train_loss_q1 | 0.0027   |
| train_loss_q2 | 0.000304 |
| train_loss_q3 | 2.39e-05 |
| train_mse_q0  | 0.0126   |
| train_mse_q1  | 0.0027   |
| train_mse_q2  | 0.000304 |
| train_mse_q3  | 2.39e-05 |
----------------------------
----------------------------
| grad_norm     | 0.015    |
| loss          | 0.00377  |
| mse           | 0.00377  |
| param_norm    | 427      |
| samples       | 1.57e+06 |
| step          | 4.9e+04  |
| train_loss_q0 | 0.0122   |
| train_loss_q1 | 0.00258  |
| train_loss_q2 | 0.000289 |
| train_loss_q3 | 2.42e-05 |
| train_mse_q0  | 0.0122   |
| train_mse_q1  | 0.00258  |
| train_mse_q2  | 0.000289 |
| train_mse_q3  | 2.42e-05 |
----------------------------
----------------------------
| grad_norm     | 0.015    |
| loss          | 0.00377  |
| mse           | 0.00377  |
| param_norm    | 428      |
| samples       | 1.6e+06  |
| step          | 5e+04    |
| train_loss_q0 | 0.0122   |
| train_loss_q1 | 0.00269  |
| train_loss_q2 | 0.000306 |
| train_loss_q3 | 2.54e-05 |
| train_mse_q0  | 0.0122   |
| train_mse_q1  | 0.00269  |
| train_mse_q2  | 0.000306 |
| train_mse_q3  | 2.54e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.0154   |
| loss          | 0.00384  |
| mse           | 0.00384  |
| param_norm    | 428      |
| samples       | 1.63e+06 |
| step          | 5.1e+04  |
| train_loss_q0 | 0.0126   |
| train_loss_q1 | 0.00252  |
| train_loss_q2 | 0.000297 |
| train_loss_q3 | 2.56e-05 |
| train_mse_q0  | 0.0126   |
| train_mse_q1  | 0.00252  |
| train_mse_q2  | 0.000297 |
| train_mse_q3  | 2.56e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0145   |
| loss          | 0.004    |
| mse           | 0.004    |
| param_norm    | 428      |
| samples       | 1.66e+06 |
| step          | 5.2e+04  |
| train_loss_q0 | 0.0137   |
| train_loss_q1 | 0.00263  |
| train_loss_q2 | 0.000298 |
| train_loss_q3 | 2.28e-05 |
| train_mse_q0  | 0.0137   |
| train_mse_q1  | 0.00263  |
| train_mse_q2  | 0.000298 |
| train_mse_q3  | 2.28e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0157   |
| loss          | 0.00412  |
| mse           | 0.00412  |
| param_norm    | 429      |
| samples       | 1.7e+06  |
| step          | 5.3e+04  |
| train_loss_q0 | 0.0136   |
| train_loss_q1 | 0.00255  |
| train_loss_q2 | 0.000302 |
| train_loss_q3 | 2.48e-05 |
| train_mse_q0  | 0.0136   |
| train_mse_q1  | 0.00255  |
| train_mse_q2  | 0.000302 |
| train_mse_q3  | 2.48e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0144   |
| loss          | 0.00408  |
| mse           | 0.00408  |
| param_norm    | 429      |
| samples       | 1.73e+06 |
| step          | 5.4e+04  |
| train_loss_q0 | 0.0126   |
| train_loss_q1 | 0.00278  |
| train_loss_q2 | 0.000309 |
| train_loss_q3 | 2.38e-05 |
| train_mse_q0  | 0.0126   |
| train_mse_q1  | 0.00278  |
| train_mse_q2  | 0.000309 |
| train_mse_q3  | 2.38e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0147   |
| loss          | 0.00386  |
| mse           | 0.00386  |
| param_norm    | 430      |
| samples       | 1.76e+06 |
| step          | 5.5e+04  |
| train_loss_q0 | 0.0123   |
| train_loss_q1 | 0.00274  |
| train_loss_q2 | 0.000334 |
| train_loss_q3 | 2.45e-05 |
| train_mse_q0  | 0.0123   |
| train_mse_q1  | 0.00274  |
| train_mse_q2  | 0.000334 |
| train_mse_q3  | 2.45e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0142   |
| loss          | 0.00377  |
| mse           | 0.00377  |
| param_norm    | 430      |
| samples       | 1.79e+06 |
| step          | 5.6e+04  |
| train_loss_q0 | 0.0123   |
| train_loss_q1 | 0.00267  |
| train_loss_q2 | 0.000325 |
| train_loss_q3 | 2.16e-05 |
| train_mse_q0  | 0.0123   |
| train_mse_q1  | 0.00267  |
| train_mse_q2  | 0.000325 |
| train_mse_q3  | 2.16e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0152   |
| loss          | 0.00382  |
| mse           | 0.00382  |
| param_norm    | 431      |
| samples       | 1.82e+06 |
| step          | 5.7e+04  |
| train_loss_q0 | 0.0126   |
| train_loss_q1 | 0.00259  |
| train_loss_q2 | 0.000299 |
| train_loss_q3 | 2.37e-05 |
| train_mse_q0  | 0.0126   |
| train_mse_q1  | 0.00259  |
| train_mse_q2  | 0.000299 |
| train_mse_q3  | 2.37e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0144   |
| loss          | 0.00395  |
| mse           | 0.00395  |
| param_norm    | 431      |
| samples       | 1.86e+06 |
| step          | 5.8e+04  |
| train_loss_q0 | 0.0128   |
| train_loss_q1 | 0.00264  |
| train_loss_q2 | 0.000314 |
| train_loss_q3 | 2.44e-05 |
| train_mse_q0  | 0.0128   |
| train_mse_q1  | 0.00264  |
| train_mse_q2  | 0.000314 |
| train_mse_q3  | 2.44e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0164   |
| loss          | 0.00389  |
| mse           | 0.00389  |
| param_norm    | 432      |
| samples       | 1.89e+06 |
| step          | 5.9e+04  |
| train_loss_q0 | 0.0128   |
| train_loss_q1 | 0.00264  |
| train_loss_q2 | 0.000322 |
| train_loss_q3 | 2.66e-05 |
| train_mse_q0  | 0.0128   |
| train_mse_q1  | 0.00264  |
| train_mse_q2  | 0.000322 |
| train_mse_q3  | 2.66e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0145   |
| loss          | 0.00379  |
| mse           | 0.00379  |
| param_norm    | 432      |
| samples       | 1.92e+06 |
| step          | 6e+04    |
| train_loss_q0 | 0.0127   |
| train_loss_q1 | 0.00272  |
| train_loss_q2 | 0.000325 |
| train_loss_q3 | 2.33e-05 |
| train_mse_q0  | 0.0127   |
| train_mse_q1  | 0.00272  |
| train_mse_q2  | 0.000325 |
| train_mse_q3  | 2.33e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.014    |
| loss          | 0.00372  |
| mse           | 0.00372  |
| param_norm    | 433      |
| samples       | 1.95e+06 |
| step          | 6.1e+04  |
| train_loss_q0 | 0.0121   |
| train_loss_q1 | 0.00268  |
| train_loss_q2 | 0.000346 |
| train_loss_q3 | 2.27e-05 |
| train_mse_q0  | 0.0121   |
| train_mse_q1  | 0.00268  |
| train_mse_q2  | 0.000346 |
| train_mse_q3  | 2.27e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0143   |
| loss          | 0.00398  |
| mse           | 0.00398  |
| param_norm    | 433      |
| samples       | 1.98e+06 |
| step          | 6.2e+04  |
| train_loss_q0 | 0.0126   |
| train_loss_q1 | 0.00269  |
| train_loss_q2 | 0.000327 |
| train_loss_q3 | 2.31e-05 |
| train_mse_q0  | 0.0126   |
| train_mse_q1  | 0.00269  |
| train_mse_q2  | 0.000327 |
| train_mse_q3  | 2.31e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0147   |
| loss          | 0.00383  |
| mse           | 0.00383  |
| param_norm    | 434      |
| samples       | 2.02e+06 |
| step          | 6.3e+04  |
| train_loss_q0 | 0.0124   |
| train_loss_q1 | 0.00259  |
| train_loss_q2 | 0.000295 |
| train_loss_q3 | 2.42e-05 |
| train_mse_q0  | 0.0124   |
| train_mse_q1  | 0.00259  |
| train_mse_q2  | 0.000295 |
| train_mse_q3  | 2.42e-05 |
----------------------------
----------------------------
| grad_norm     | 0.015    |
| loss          | 0.0038   |
| mse           | 0.0038   |
| param_norm    | 434      |
| samples       | 2.05e+06 |
| step          | 6.4e+04  |
| train_loss_q0 | 0.0124   |
| train_loss_q1 | 0.00262  |
| train_loss_q2 | 0.000308 |
| train_loss_q3 | 2.4e-05  |
| train_mse_q0  | 0.0124   |
| train_mse_q1  | 0.00262  |
| train_mse_q2  | 0.000308 |
| train_mse_q3  | 2.4e-05  |
----------------------------
----------------------------
| grad_norm     | 0.0145   |
| loss          | 0.00389  |
| mse           | 0.00389  |
| param_norm    | 434      |
| samples       | 2.08e+06 |
| step          | 6.5e+04  |
| train_loss_q0 | 0.0122   |
| train_loss_q1 | 0.0026   |
| train_loss_q2 | 0.000297 |
| train_loss_q3 | 2.5e-05  |
| train_mse_q0  | 0.0122   |
| train_mse_q1  | 0.0026   |
| train_mse_q2  | 0.000297 |
| train_mse_q3  | 2.5e-05  |
----------------------------
----------------------------
| grad_norm     | 0.0139   |
| loss          | 0.00364  |
| mse           | 0.00364  |
| param_norm    | 435      |
| samples       | 2.11e+06 |
| step          | 6.6e+04  |
| train_loss_q0 | 0.0123   |
| train_loss_q1 | 0.00252  |
| train_loss_q2 | 0.0003   |
| train_loss_q3 | 2.39e-05 |
| train_mse_q0  | 0.0123   |
| train_mse_q1  | 0.00252  |
| train_mse_q2  | 0.0003   |
| train_mse_q3  | 2.39e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0139   |
| loss          | 0.00393  |
| mse           | 0.00393  |
| param_norm    | 435      |
| samples       | 2.14e+06 |
| step          | 6.7e+04  |
| train_loss_q0 | 0.0121   |
| train_loss_q1 | 0.00278  |
| train_loss_q2 | 0.000312 |
| train_loss_q3 | 2.24e-05 |
| train_mse_q0  | 0.0121   |
| train_mse_q1  | 0.00278  |
| train_mse_q2  | 0.000312 |
| train_mse_q3  | 2.24e-05 |
----------------------------
----------------------------
| grad_norm     | 0.015    |
| loss          | 0.00378  |
| mse           | 0.00378  |
| param_norm    | 436      |
| samples       | 2.18e+06 |
| step          | 6.8e+04  |
| train_loss_q0 | 0.0118   |
| train_loss_q1 | 0.00254  |
| train_loss_q2 | 0.000293 |
| train_loss_q3 | 2.28e-05 |
| train_mse_q0  | 0.0118   |
| train_mse_q1  | 0.00254  |
| train_mse_q2  | 0.000293 |
| train_mse_q3  | 2.28e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0144   |
| loss          | 0.004    |
| mse           | 0.004    |
| param_norm    | 436      |
| samples       | 2.21e+06 |
| step          | 6.9e+04  |
| train_loss_q0 | 0.013    |
| train_loss_q1 | 0.00271  |
| train_loss_q2 | 0.000308 |
| train_loss_q3 | 2.39e-05 |
| train_mse_q0  | 0.013    |
| train_mse_q1  | 0.00271  |
| train_mse_q2  | 0.000308 |
| train_mse_q3  | 2.39e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0145   |
| loss          | 0.00371  |
| mse           | 0.00371  |
| param_norm    | 436      |
| samples       | 2.24e+06 |
| step          | 7e+04    |
| train_loss_q0 | 0.012    |
| train_loss_q1 | 0.00263  |
| train_loss_q2 | 0.000325 |
| train_loss_q3 | 2.36e-05 |
| train_mse_q0  | 0.012    |
| train_mse_q1  | 0.00263  |
| train_mse_q2  | 0.000325 |
| train_mse_q3  | 2.36e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.0142   |
| loss          | 0.00395  |
| mse           | 0.00395  |
| param_norm    | 437      |
| samples       | 2.27e+06 |
| step          | 7.1e+04  |
| train_loss_q0 | 0.0124   |
| train_loss_q1 | 0.00287  |
| train_loss_q2 | 0.000311 |
| train_loss_q3 | 2.38e-05 |
| train_mse_q0  | 0.0124   |
| train_mse_q1  | 0.00287  |
| train_mse_q2  | 0.000311 |
| train_mse_q3  | 2.38e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0137   |
| loss          | 0.00385  |
| mse           | 0.00385  |
| param_norm    | 437      |
| samples       | 2.3e+06  |
| step          | 7.2e+04  |
| train_loss_q0 | 0.0131   |
| train_loss_q1 | 0.00254  |
| train_loss_q2 | 0.000291 |
| train_loss_q3 | 2.22e-05 |
| train_mse_q0  | 0.0131   |
| train_mse_q1  | 0.00254  |
| train_mse_q2  | 0.000291 |
| train_mse_q3  | 2.22e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0152   |
| loss          | 0.00396  |
| mse           | 0.00396  |
| param_norm    | 438      |
| samples       | 2.34e+06 |
| step          | 7.3e+04  |
| train_loss_q0 | 0.0133   |
| train_loss_q1 | 0.00242  |
| train_loss_q2 | 0.000346 |
| train_loss_q3 | 2.43e-05 |
| train_mse_q0  | 0.0133   |
| train_mse_q1  | 0.00242  |
| train_mse_q2  | 0.000346 |
| train_mse_q3  | 2.43e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0143   |
| loss          | 0.00391  |
| mse           | 0.00391  |
| param_norm    | 438      |
| samples       | 2.37e+06 |
| step          | 7.4e+04  |
| train_loss_q0 | 0.0124   |
| train_loss_q1 | 0.0027   |
| train_loss_q2 | 0.000295 |
| train_loss_q3 | 2.39e-05 |
| train_mse_q0  | 0.0124   |
| train_mse_q1  | 0.0027   |
| train_mse_q2  | 0.000295 |
| train_mse_q3  | 2.39e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0139   |
| loss          | 0.00391  |
| mse           | 0.00391  |
| param_norm    | 439      |
| samples       | 2.4e+06  |
| step          | 7.5e+04  |
| train_loss_q0 | 0.0126   |
| train_loss_q1 | 0.00273  |
| train_loss_q2 | 0.00029  |
| train_loss_q3 | 2.24e-05 |
| train_mse_q0  | 0.0126   |
| train_mse_q1  | 0.00273  |
| train_mse_q2  | 0.00029  |
| train_mse_q3  | 2.24e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0137   |
| loss          | 0.00392  |
| mse           | 0.00392  |
| param_norm    | 439      |
| samples       | 2.43e+06 |
| step          | 7.6e+04  |
| train_loss_q0 | 0.0127   |
| train_loss_q1 | 0.0027   |
| train_loss_q2 | 0.000321 |
| train_loss_q3 | 2.36e-05 |
| train_mse_q0  | 0.0127   |
| train_mse_q1  | 0.0027   |
| train_mse_q2  | 0.000321 |
| train_mse_q3  | 2.36e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0143   |
| loss          | 0.00386  |
| mse           | 0.00386  |
| param_norm    | 440      |
| samples       | 2.46e+06 |
| step          | 7.7e+04  |
| train_loss_q0 | 0.0129   |
| train_loss_q1 | 0.00266  |
| train_loss_q2 | 0.000301 |
| train_loss_q3 | 2.36e-05 |
| train_mse_q0  | 0.0129   |
| train_mse_q1  | 0.00266  |
| train_mse_q2  | 0.000301 |
| train_mse_q3  | 2.36e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0139   |
| loss          | 0.00401  |
| mse           | 0.00401  |
| param_norm    | 440      |
| samples       | 2.5e+06  |
| step          | 7.8e+04  |
| train_loss_q0 | 0.0132   |
| train_loss_q1 | 0.00271  |
| train_loss_q2 | 0.00031  |
| train_loss_q3 | 2.29e-05 |
| train_mse_q0  | 0.0132   |
| train_mse_q1  | 0.00271  |
| train_mse_q2  | 0.00031  |
| train_mse_q3  | 2.29e-05 |
----------------------------
----------------------------
| grad_norm     | 0.014    |
| loss          | 0.00384  |
| mse           | 0.00384  |
| param_norm    | 440      |
| samples       | 2.53e+06 |
| step          | 7.9e+04  |
| train_loss_q0 | 0.0124   |
| train_loss_q1 | 0.00249  |
| train_loss_q2 | 0.000281 |
| train_loss_q3 | 2.44e-05 |
| train_mse_q0  | 0.0124   |
| train_mse_q1  | 0.00249  |
| train_mse_q2  | 0.000281 |
| train_mse_q3  | 2.44e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0145   |
| loss          | 0.00408  |
| mse           | 0.00408  |
| param_norm    | 441      |
| samples       | 2.56e+06 |
| step          | 8e+04    |
| train_loss_q0 | 0.0131   |
| train_loss_q1 | 0.00259  |
| train_loss_q2 | 0.000294 |
| train_loss_q3 | 2.38e-05 |
| train_mse_q0  | 0.0131   |
| train_mse_q1  | 0.00259  |
| train_mse_q2  | 0.000294 |
| train_mse_q3  | 2.38e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 0.0142   |
| loss          | 0.00399  |
| mse           | 0.00399  |
| param_norm    | 441      |
| samples       | 2.59e+06 |
| step          | 8.1e+04  |
| train_loss_q0 | 0.0128   |
| train_loss_q1 | 0.00259  |
| train_loss_q2 | 0.000304 |
| train_loss_q3 | 2.21e-05 |
| train_mse_q0  | 0.0128   |
| train_mse_q1  | 0.00259  |
| train_mse_q2  | 0.000304 |
| train_mse_q3  | 2.21e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0143   |
| loss          | 0.00412  |
| mse           | 0.00412  |
| param_norm    | 442      |
| samples       | 2.62e+06 |
| step          | 8.2e+04  |
| train_loss_q0 | 0.0131   |
| train_loss_q1 | 0.00267  |
| train_loss_q2 | 0.000306 |
| train_loss_q3 | 2.42e-05 |
| train_mse_q0  | 0.0131   |
| train_mse_q1  | 0.00267  |
| train_mse_q2  | 0.000306 |
| train_mse_q3  | 2.42e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0137   |
| loss          | 0.00388  |
| mse           | 0.00388  |
| param_norm    | 442      |
| samples       | 2.66e+06 |
| step          | 8.3e+04  |
| train_loss_q0 | 0.0124   |
| train_loss_q1 | 0.00262  |
| train_loss_q2 | 0.000306 |
| train_loss_q3 | 2.35e-05 |
| train_mse_q0  | 0.0124   |
| train_mse_q1  | 0.00262  |
| train_mse_q2  | 0.000306 |
| train_mse_q3  | 2.35e-05 |
----------------------------
----------------------------
| grad_norm     | 0.0144   |
| loss          | 0.00396  |
| mse           | 0.00396  |
| param_norm    | 443      |
| samples       | 2.69e+06 |
| step          | 8.4e+04  |
| train_loss_q0 | 0.0134   |
| train_loss_q1 | 0.00266  |
| train_loss_q2 | 0.0003   |
| train_loss_q3 | 2.41e-05 |
| train_mse_q0  | 0.0134   |
| train_mse_q1  | 0.00266  |
| train_mse_q2  | 0.0003   |
| train_mse_q3  | 2.41e-05 |
----------------------------
